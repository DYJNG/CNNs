{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet的实现及在cifar10上的应用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导入包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dyjng/anaconda3/lib/python3.6/site-packages/urllib3/contrib/pyopenssl.py:46: DeprecationWarning: OpenSSL.rand is deprecated - you should use os.urandom instead\n",
      "  import OpenSSL.SSL\n"
     ]
    }
   ],
   "source": [
    "import mxnet as mx\n",
    "from mxnet import ndarray as nd\n",
    "from mxnet import autograd as ag\n",
    "from mxnet import init\n",
    "from mxnet import gluon\n",
    "from mxnet.gluon.data import vision\n",
    "from mxnet.gluon.data.vision import transforms\n",
    "from mxnet.gluon import nn\n",
    "import datetime\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.dpi'] = 120\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据增广"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "#     transforms.CenterCrop(224),\n",
    "#     transforms.RandomFlipTopBottom(),\n",
    "#     transforms.RandomColorJitter(brightness=0.0, contrast=0.0, saturation=0.0, hue=0.0),\n",
    "#     transforms.RandomLighting(0.0),\n",
    "#     transforms.Cast('float32'),\n",
    "    transforms.Resize(224),\n",
    "    \n",
    "    # 随机按照 scale 和 ratio 裁剪， 并放缩为 227*227 #(32x32) 的正方形\n",
    "    transforms.RandomResizedCrop(224, scale=(0.08, 1.0), ratio=(3.0/4.0, 4.0/3.0)),\n",
    "    transforms.RandomFlipLeftRight(),\n",
    "    # 将像素值缩小到 (0, 1) 内， 并将数据格式从 “ 高 × 宽 × 通道 ” 改为 “ 通道 × 高 × 宽”\n",
    "    transforms.ToTensor(),\n",
    "    # 对图片的每个通道做标准化 --减去均值，除以方差\n",
    "    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.2010]),\n",
    "])\n",
    "transform_valid = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.2010])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读取数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = 'data/cifar10/'\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "train_ds = vision.ImageFolderDataset(root=data_dir+'train', flag=1)\n",
    "valid_ds = vision.ImageFolderDataset(root=data_dir+'valid', flag=1)\n",
    "\n",
    "train_data = gluon.data.DataLoader(dataset=train_ds.transform_first(transform_train), \n",
    "                                   batch_size=batch_size, shuffle=True, last_batch='keep')\n",
    "valid_data = gluon.data.DataLoader(dataset=valid_ds.transform_first(transform_valid), \n",
    "                                   batch_size=batch_size, shuffle=False, last_batch='keep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45000\n",
      "5000\n",
      "704\n",
      "(64, 3, 224, 224) (64,)\n",
      "\n",
      "[0 7 8 2 3 9 9 6 2 8 0 5 5 3 1 2 6 3 2 8 2 8 8 2 1 7 9 7 9 1 2 9 3 0 5 4 2\n",
      " 7 1 3 7 6 9 7 2 7 6 7 7 5 0 9 1 2 2 7 4 0 5 2 3 3 2 4]\n",
      "<NDArray 64 @gpu(0)>\n"
     ]
    }
   ],
   "source": [
    "print(len(train_ds))\n",
    "print(len(valid_ds))\n",
    "\n",
    "print(len(train_data))\n",
    "for data, label in train_data:\n",
    "    print(data.shape, label.shape)\n",
    "    print(label.as_in_context(mx.gpu(0)))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 交叉熵损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "softmax_cross_entropy = gluon.loss.SoftmaxCrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 设计模型 --ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class residual_block(nn.HybridBlock):\n",
    "    def __init__(self, channels, same_shape=True, first_residual=False, **kwargs):\n",
    "        super(residual_block, self).__init__(**kwargs)\n",
    "        self.same_shape = same_shape\n",
    "        self.first_residual = first_residual\n",
    "        strides = 1 if same_shape else 2\n",
    "        with self.name_scope():\n",
    "            self.bn1 = nn.BatchNorm()\n",
    "            self.conv1 = nn.Conv2D(channels=channels, kernel_size=1, \n",
    "                                   strides=strides, padding=0)\n",
    "            self.bn2 = nn.BatchNorm()\n",
    "            self.conv2 = nn.Conv2D(channels=channels, kernel_size=3, \n",
    "                                   strides=1, padding=1)\n",
    "            self.bn3 = nn.BatchNorm()\n",
    "            self.conv3 = nn.Conv2D(channels=4*channels, kernel_size=1, \n",
    "                                   strides=1, padding=0)\n",
    "            if not same_shape:\n",
    "                self.conv4 = nn.Conv2D(channels=4*channels, kernel_size=1, \n",
    "                                       strides=strides, padding=0)\n",
    "            elif first_residual:\n",
    "                self.conv4 = nn.Conv2D(channels=4*channels, kernel_size=1, \n",
    "                                       strides=strides, padding=0)\n",
    "    \n",
    "    def hybrid_forward(self, F, x):\n",
    "        x = F.relu(self.bn1(x))\n",
    "        out = self.conv1(x)\n",
    "        out = self.conv2(F.relu(self.bn2(out)))\n",
    "        out = self.conv3(F.relu(self.bn3(out)))\n",
    "        if not self.same_shape or self.first_residual:\n",
    "            x = self.conv4(x)\n",
    "        return out + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ResNet50(nn.HybridBlock):\n",
    "    def __init__(self, num_classes, verbose=False, **kwargs):\n",
    "        super(ResNet50, self).__init__(**kwargs)\n",
    "        self.verbose = verbose\n",
    "        with self.name_scope():\n",
    "            net = self.net = nn.HybridSequential()\n",
    "            # stage 1\n",
    "#             net.add(nn.BatchNorm())\n",
    "#             net.add(nn.Activation(activation='relu'))\n",
    "            net.add(nn.Conv2D(channels=64, kernel_size=7, \n",
    "                              strides=2, padding=3))\n",
    "            net.add(nn.BatchNorm())\n",
    "            net.add(nn.Activation(activation='relu'))\n",
    "            net.add(nn.MaxPool2D(pool_size=3, strides=2, padding=1))\n",
    "            # stage 2\n",
    "            net.add(residual_block(64, first_residual=True))\n",
    "            for _ in range(2):\n",
    "                net.add(residual_block(64))\n",
    "            # stage 3\n",
    "            net.add(residual_block(128, same_shape=False))\n",
    "            for _ in range(3):\n",
    "                net.add(residual_block(128))\n",
    "            # stage 4\n",
    "            net.add(residual_block(256, same_shape=False))\n",
    "            for _ in range(5):\n",
    "                net.add(residual_block(256))\n",
    "            # stage 5\n",
    "            net.add(residual_block(512, same_shape=False))\n",
    "            for _ in range(2):\n",
    "                net.add(residual_block(512))\n",
    "            # stage 6\n",
    "            net.add(nn.BatchNorm())\n",
    "            net.add(nn.Activation(activation='relu'))\n",
    "            net.add(nn.AvgPool2D(pool_size=7))\n",
    "            net.add(nn.Flatten())\n",
    "            net.add(nn.Dense(num_classes))\n",
    "            \n",
    "    def hybrid_forward(self, F, x):\n",
    "        out = x\n",
    "        for i, f in enumerate(self.net):\n",
    "            out = f(out)\n",
    "            if self.verbose:\n",
    "                print('Block %d, Output: %s' % (i+1, out.shape))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_net(ctx, num_classes=1000):\n",
    "    net = ResNet50(num_classes=num_classes)\n",
    "    net.initialize(ctx=ctx, init=init.Xavier())\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net = ResNet50(num_classes=100, verbose=True)\n",
    "# net.initialize()\n",
    "# net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for data, label in train_data:\n",
    "#     out = net(data)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# a = True\n",
    "# b = False\n",
    "# conv = 0\n",
    "# if a:\n",
    "#     conv = 1\n",
    "# elif b:\n",
    "#     conv = 2\n",
    "# if not a or b:\n",
    "#     print(conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def train(net, train_data, valid_data, ctx, num_epoches, optimizer='adam', \n",
    "#           lr=0.01, lr_decay=0.1, lr_period=50, momentum=0.9, weight_decay=0, \n",
    "#           cost_peroid=10, print_cost=False):\n",
    "#     if optimizer == 'momentum':\n",
    "#         trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': lr, \n",
    "#                                                               'momentum': momentum, \n",
    "#                                                               'wd': weight_decay})\n",
    "#     elif optimizer == 'adam':\n",
    "#         trainer = gluon.Trainer(net.collect_params(), 'adam', {'learning_rate': lr, \n",
    "#                                                                'wd': weight_decay})\n",
    "    \n",
    "#     train_costs = []\n",
    "#     valid_costs = []\n",
    "#     v_loss_train = 0\n",
    "#     n_iter_train = 0\n",
    "# #     v_loss_valid = 0\n",
    "# #     n_iter_valid = 0\n",
    "#     for epoch in range(num_epoches):\n",
    "#         pre_time = datetime.datetime.now()\n",
    "#         train_acc = 0\n",
    "# #         train_loss = 0\n",
    "#         if (epoch+1) % lr_period == 0:\n",
    "#             trainer.set_learning_rate(trainer.learning_rate * lr_decay)\n",
    "#         for data, label in train_data:\n",
    "#             data = data.as_in_context(ctx)\n",
    "#             label = label.astype('float32').as_in_context(ctx)\n",
    "#             with ag.record():\n",
    "#                 output = net(data)\n",
    "#                 loss = softmax_cross_entropy(output, label)\n",
    "#             loss.backward()\n",
    "#             trainer.step(batch_size)\n",
    "#             train_acc += nd.mean(output.argmax(axis=1) == label).asscalar()\n",
    "# #             train_loss += nd.mean(loss).asscalar()\n",
    "#             cur_loss = nd.mean(loss).asscalar()\n",
    "#             v_loss_train = 0.9 * v_loss_train + 0.1 * cur_loss\n",
    "#             n_iter_train += 1\n",
    "#             corr_loss_train = v_loss_train / (1 - pow(0.9, n_iter_train))\n",
    "            \n",
    "#         cur_time = datetime.datetime.now()\n",
    "#         h, remainder = divmod((cur_time - pre_time).seconds, 3600)\n",
    "#         m, s = divmod(remainder, 60)\n",
    "#         time_str = 'Time %02d:%02d:%02d, ' % (h, m, s)\n",
    "        \n",
    "#         if valid_data is not None:\n",
    "#             valid_acc = 0\n",
    "#             valid_loss = 0\n",
    "#             for data, label in valid_data:\n",
    "#                 data = data.as_in_context(ctx)\n",
    "#                 label = label.astype('float32').as_in_context(ctx)\n",
    "#                 output = net(data)\n",
    "#                 loss = softmax_cross_entropy(output, label)\n",
    "#                 valid_acc += nd.mean(output.argmax(axis=1) == label).asscalar()\n",
    "# #                 cur_loss = nd.mean(loss).asscalar()\n",
    "# #                 v_loss_valid = 0.9 * v_loss_valid + 0.1 * cur_loss\n",
    "# #                 n_iter_valid += 1\n",
    "# #                 corr_loss_valid = v_loss_valid / (1 - pow(0.9, n_iter_valid))\n",
    "#                 valid_loss += nd.mean(loss).asscalar()\n",
    "#             epoch_str = 'Epoch %d, Train_loss: %s, Train_acc: %s, Valid_acc: %s, ' % (epoch+1, \n",
    "#                                                                                     corr_loss_train, \n",
    "#                                                                                     train_acc/len(train_data), \n",
    "#                                                                                     valid_acc/len(valid_data))\n",
    "#         else:\n",
    "#             epoch_str = 'Epoch %d, Train_loss: %s, Train_acc: %s, ' % (epoch+1, \n",
    "#                                                                      corr_loss_train, \n",
    "#                                                                      train_acc/len(train_data))\n",
    "#         if print_cost and (epoch+1) % cost_peroid == 0:\n",
    "#             train_costs.append(corr_loss_train)\n",
    "# #             train_costs.append(train_loss/len(train_data))\n",
    "#             valid_costs.append(valid_loss/len(valid_data))\n",
    "        \n",
    "#         print(epoch_str + time_str + 'lr: %f' % trainer.learning_rate)\n",
    "        \n",
    "#     if print_cost:\n",
    "#         x_axis = np.linspace(0, num_epoches, len(train_costs), endpoint=True)\n",
    "#         train, = plt.semilogy(x_axis, train_costs)\n",
    "#         valid, = plt.semilogy(x_axis, valid_costs)\n",
    "#         plt.xlabel('epoch')\n",
    "#         plt.ylabel('loss')\n",
    "#         plt.legend(loc='upper right')\n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ctx = mx.gpu(0)\n",
    "num_epoches = 1\n",
    "optimizer = 'momentum'\n",
    "lr = 0.1\n",
    "lr_decay = 0.1\n",
    "lr_period = 50\n",
    "momentum = 0.9\n",
    "weight_decay = 0\n",
    "cost_peroid = 1\n",
    "print_cost = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = get_net(ctx, num_classes=10)\n",
    "net.hybridize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train_loss: 1.78713667901, Train_acc: 0.27949662642, Valid_acc: 0.405261075949, Time 00:04:38, lr: 0.100000\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAl8AAAG2CAYAAABBHOPKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5f04119f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "utils.train(net, train_data, valid_data, ctx, num_epoches, softmax_cross_entropy, optimizer, \n",
    "      lr, lr_decay, lr_period, momentum, weight_decay, \n",
    "      cost_peroid, print_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# str = ''\n",
    "# # str = str + 'a' + '' + 'b'\n",
    "# print(len(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for i in range(0):\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
