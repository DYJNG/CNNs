{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AlexNet的实现及在cifar10上的应用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导入包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dyjng/anaconda3/lib/python3.6/site-packages/urllib3/contrib/pyopenssl.py:46: DeprecationWarning: OpenSSL.rand is deprecated - you should use os.urandom instead\n",
      "  import OpenSSL.SSL\n"
     ]
    }
   ],
   "source": [
    "import mxnet as mx\n",
    "from mxnet import gluon\n",
    "from mxnet import ndarray as nd\n",
    "from mxnet import autograd as ag\n",
    "from mxnet import init\n",
    "from mxnet.gluon.data import vision\n",
    "from mxnet.gluon.data.vision import transforms\n",
    "from mxnet.gluon import nn\n",
    "import datetime\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.dpi'] = 120\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据增广"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "#     transforms.CenterCrop(32),\n",
    "#     transforms.RandomFlipTopBottom(),\n",
    "#     transforms.RandomColorJitter(brightness=0.0, contrast=0.0, saturation=0.0, hue=0.0),\n",
    "#     transforms.RandomLighting(0.0),\n",
    "#     transforms.Cast('float32'),\n",
    "#     transforms.Resize(32),\n",
    "    transforms.Resize(227),\n",
    "    \n",
    "    # 随机按照 scale 和 ratio 裁剪， 并放缩为 227*227 #(32x32) 的正方形\n",
    "    transforms.RandomResizedCrop(227, scale=(0.08, 1.0), ratio=(3.0/4.0, 4.0/3.0)),\n",
    "    transforms.RandomFlipLeftRight(),\n",
    "    # 将像素值缩小到 (0, 1) 内， 并将数据格式从 “ 高 × 宽 × 通道 ” 改为 “ 通道 × 高 × 宽”\n",
    "    transforms.ToTensor(),\n",
    "    # 对图片的每个通道做标准化 --减去均值，除以方差\n",
    "    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.2010])\n",
    "    \n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize(227),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.2010])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读取数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = 'data/cifar10/'\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "# 读取原始图像文件， flag = 1 表示图像有三个通道（彩色）\n",
    "train_ds = vision.ImageFolderDataset(data_dir + 'train', flag=1)\n",
    "valid_ds = vision.ImageFolderDataset(data_dir + 'valid', flag=1)\n",
    "\n",
    "loader = gluon.data.DataLoader\n",
    "train_data = loader(train_ds.transform_first(transform_train), \n",
    "                    batch_size, shuffle=True, last_batch='keep')\n",
    "valid_data = loader(valid_ds.transform_first(transform_test), \n",
    "                    batch_size, shuffle=False, last_batch='keep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45000\n",
      "5000\n",
      "352\n",
      "(128, 3, 227, 227) (128,)\n",
      "\n",
      "[4 1 7 7 1 6 0 8 2 8 2 2 7 7 2 7 4 8 0 9 6 1 1 4 2 1 9 4 8 2 2 8 8 1 4 1 2\n",
      " 2 1 9 8 2 5 1 7 5 4 2 7 3 5 4 5 0 7 7 6 5 1 0 1 3 2 7 9 1 4 8 3 3 2 2 3 0\n",
      " 0 7 7 9 1 7 3 9 1 7 9 0 6 0 7 5 9 7 8 7 5 1 0 0 7 5 3 0 2 9 6 3 0 4 5 8 0\n",
      " 0 3 6 2 7 6 8 7 5 1 2 9 9 1 9 1 6]\n",
      "<NDArray 128 @gpu(0)>\n"
     ]
    }
   ],
   "source": [
    "print(len(train_ds))\n",
    "print(len(valid_ds))\n",
    "\n",
    "print(len(train_data))\n",
    "for data, label in train_data:\n",
    "    print(data.shape, label.shape)\n",
    "    print(label.as_in_context(mx.gpu(0)))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 交叉熵损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "softmax_cross_entropy = gluon.loss.SoftmaxCrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 设计模型 --AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AlexNet(nn.HybridBlock):\n",
    "    def __init__(self, num_classes, verbose=False, **kwargs):\n",
    "        super(AlexNet, self).__init__(**kwargs)\n",
    "        self.verbose = verbose\n",
    "        with self.name_scope():\n",
    "            net = self.net = nn.HybridSequential()\n",
    "            # conv1\n",
    "            net.add(nn.Conv2D(channels=96, kernel_size=11, \n",
    "                              strides=4, padding=0))\n",
    "            net.add(nn.BatchNorm())\n",
    "            net.add(nn.Activation(activation='relu'))\n",
    "            net.add(nn.MaxPool2D(pool_size=3, strides=2))\n",
    "            # conv2\n",
    "            net.add(nn.Conv2D(channels=256, kernel_size=5, \n",
    "                              strides=1, padding=2))\n",
    "            net.add(nn.BatchNorm())\n",
    "            net.add(nn.Activation(activation='relu'))\n",
    "            net.add(nn.MaxPool2D(pool_size=3, strides=2))\n",
    "            # conv3\n",
    "            net.add(nn.Conv2D(channels=384, kernel_size=3, \n",
    "                              strides=1, padding=1))\n",
    "            net.add(nn.BatchNorm())\n",
    "            net.add(nn.Activation(activation='relu'))\n",
    "            # conv4\n",
    "            net.add(nn.Conv2D(channels=384, kernel_size=3, \n",
    "                              strides=1, padding=1))\n",
    "            net.add(nn.BatchNorm())\n",
    "            net.add(nn.Activation(activation='relu'))\n",
    "            # conv5\n",
    "            net.add(nn.Conv2D(channels=256, kernel_size=3, \n",
    "                              strides=1, padding=1))\n",
    "            net.add(nn.BatchNorm())\n",
    "            net.add(nn.Activation(activation='relu'))\n",
    "            net.add(nn.MaxPool2D(pool_size=3, strides=2))\n",
    "            \n",
    "            # FC\n",
    "            net.add(nn.Flatten())\n",
    "            net.add(nn.Dense(4096))\n",
    "            net.add(nn.Dropout(0.5))\n",
    "            net.add(nn.Dense(4096))\n",
    "            net.add(nn.Dropout(0.5))\n",
    "            net.add(nn.Dense(num_classes))\n",
    "    \n",
    "    def hybrid_forward(self, F, x):   # __init__() 里的 self\n",
    "        out = x\n",
    "        for i, f in enumerate(self.net):\n",
    "            out = f(out)\n",
    "            if self.verbose:\n",
    "                print('Block %d Output: %s' % (i+1, out.shape))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_net(ctx, num_classes=10):\n",
    "    net = AlexNet(num_classes)\n",
    "    net.initialize(ctx=ctx, init=init.Xavier())\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(train_data, valid_data, net, ctx, num_epoches, \n",
    "          learning_rate=0.01, lr_decay=0.1, lr_period=50, \n",
    "          momentum = 0.9, weight_decay=0, cost_period = 10, \n",
    "          print_cost=False):\n",
    "    costs = []\n",
    "    valid_costs = []\n",
    "    trainer = gluon.Trainer(net.collect_params(), 'sgd', \n",
    "                            {'learning_rate': learning_rate, \n",
    "                             'momentum': momentum, \n",
    "                             'wd': weight_decay})\n",
    "    pre_time = datetime.datetime.now()\n",
    "#     moving_loss = 0\n",
    "#     niter = 0\n",
    "    for epoch in range(num_epoches):\n",
    "        train_loss = 0\n",
    "        train_acc = 0\n",
    "        if (epoch+1) % lr_period == 0:\n",
    "            trainer.set_learning_rate(trainer.learning_rate * lr_decay)\n",
    "        for data, label in train_data:\n",
    "            data = data.as_in_context(ctx)\n",
    "#             label = label.as_in_context(ctx)\n",
    "            label = label.astype('float32').as_in_context(ctx)\n",
    "            with ag.record():\n",
    "                output = net(data)\n",
    "                loss = softmax_cross_entropy(output, label)\n",
    "            loss.backward()\n",
    "            trainer.step(batch_size)\n",
    "            train_loss += nd.mean(loss).asscalar()\n",
    "#             print(output.argmax(axis=1).astype(np.int64), label)\n",
    "            train_acc += nd.mean(output.argmax(axis=1) == label).asscalar()\n",
    "#             train_acc += nd.mean(output.argmax(axis=1).astype(np.int64) == label).asscalar()\n",
    "#             niter += 1\n",
    "#             cur_loss = nd.mean(loss).asscalar()\n",
    "#             moving_loss = 0.9 * moving_loss + 0.1 * cur_loss\n",
    "#             corr_loss = moving_loss / (1 - pow(0.9, niter))\n",
    "        cur_time = datetime.datetime.now()\n",
    "        h, remainder = divmod((cur_time - pre_time).seconds, 3600)\n",
    "        m, s = divmod(remainder, 60)\n",
    "        time_str = \"Time %02d:%02d:%02d\" % (h, m, s)\n",
    "        if valid_data is not None:\n",
    "            valid_loss = 0\n",
    "            valid_acc = 0\n",
    "            for data, label in valid_data:\n",
    "                data = data.as_in_context(ctx)\n",
    "#                 label = label.as_in_context(ctx)\n",
    "                label = label.astype('float32').as_in_context(ctx)\n",
    "                output = net(data)\n",
    "                valid_loss += nd.mean(softmax_cross_entropy(output, label)).asscalar()\n",
    "#                 valid_acc += nd.mean(output.argmax(axis=1).astype(np.int64) == label).asscalar()\n",
    "                valid_acc += nd.mean(output.argmax(axis=1) == label).asscalar()\n",
    "            epoch_str = \"Epoch %d, train_loss: %f, train_acc: %f, valid_acc %f, \" % (epoch+1, \n",
    "                                                                                   train_loss/len(train_data), \n",
    "                                                                                   train_acc/len(train_data), \n",
    "                                                                                   valid_acc/len(valid_data))\n",
    "        else:\n",
    "            epoch_str = \"Epoch %d, train_loss: %f, train_acc: %f, \" % (epoch+1, \n",
    "                                                                     train_loss/len(train_data), \n",
    "                                                                     train_acc/len(train_data))\n",
    "        if print_cost and (epoch+1) % cost_period == 0:\n",
    "#             costs.append(corr_loss)\n",
    "            costs.append(train_loss/len(train_data))\n",
    "            valid_costs.append(valid_loss/len(valid_data))\n",
    "        print(epoch_str + time_str + ', lr: %f' % trainer.learning_rate)\n",
    "        pre_time = cur_time\n",
    "    if print_cost:\n",
    "        x_axis = np.linspace(0, num_epoches, len(costs), endpoint = True)\n",
    "        plt.semilogy(x_axis, costs)\n",
    "#         plt.semilogy(x_axis, valid_costs)\n",
    "        plt.xlabel('epoch')\n",
    "        plt.ylabel('loss')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ctx = mx.gpu(0)\n",
    "num_epoches = 300\n",
    "learning_rate = 0.003\n",
    "lr_decay = 0.1\n",
    "lr_period = 50\n",
    "momentum = 0.9\n",
    "weight_decay = 0 \n",
    "cost_period = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_net' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-11d22973935a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhybridize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m train(train_data, valid_data, net, ctx, num_epoches, \n\u001b[1;32m      4\u001b[0m       \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_decay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_period\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m       \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost_period\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_net' is not defined"
     ]
    }
   ],
   "source": [
    "net = get_net(ctx, num_classes=10)\n",
    "net.hybridize()\n",
    "train(train_data, valid_data, net, ctx, num_epoches, \n",
    "      learning_rate, lr_decay, lr_period, \n",
    "      momentum, weight_decay, cost_period, \n",
    "      print_cost=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jun 20 22:01:52 2018       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 384.130                Driver Version: 384.130                   |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  GeForce GTX 108...  Off  | 00000000:29:00.0  On |                  N/A |\r\n",
      "| 15%   56C    P2    65W / 280W |   3670MiB / 11169MiB |     28%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0      1403      G   /usr/lib/xorg/Xorg                           108MiB |\r\n",
      "|    0      2130      G   compiz                                       167MiB |\r\n",
      "|    0      8627      G   /opt/teamviewer/tv_bin/TeamViewer             17MiB |\r\n",
      "|    0     21221      C   /home/dyjng/anaconda3/bin/python            3365MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-81-7e7cc9c1fb35>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "a = 'abcbdefg'\n",
    "b = list(a)\n",
    "c = list('igk')\n",
    "b = c\n",
    "b = []\n",
    "print(b[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "while i < 5:\n",
    "    i += 1\n",
    "    if i == 2:\n",
    "        i += 2\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = 0\n",
    "flag = 0\n",
    "for i in range(len(s)):\n",
    "    if s_map[s[i]] < 0:\n",
    "        if i == 0:\n",
    "            return False\n",
    "        else:\n",
    "            t += 1\n",
    "            flag -= 1\n",
    "            if s_map[s[i]] + s_map[s[i-(2*t-1)]] != 0:\n",
    "                return False\n",
    "    else:\n",
    "        t = 0\n",
    "        flag += 1\n",
    "if flag == 0:\n",
    "    return True\n",
    "else:\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Solution:\n",
    "    def isValid(self, s):\n",
    "        \"\"\"\n",
    "        :type s: str\n",
    "        :rtype: bool\n",
    "        \"\"\"\n",
    "        s_map = {'(': 1, '[': 2, '{': 3, ')': -1, ']': -2, '}': -3}\n",
    "        s_list = list(s)\n",
    "        for _ in range(int(len(s)/2) + 1):\n",
    "            i = 0\n",
    "            s_result = list()\n",
    "            if len(s_list) %2 != 0:\n",
    "                return False\n",
    "            while i < len(s_list) - 1:\n",
    "                if s_map[s_list[i]] + s_map[s_list[i+1]] != 0:\n",
    "                    s_result.append(s_list[i])\n",
    "                else:\n",
    "                    i += 1\n",
    "                i += 1\n",
    "            if i == len(s_list) - 1:\n",
    "                s_result.append(s_list[i])\n",
    "            if len(s_list) == 0:\n",
    "                return True\n",
    "            elif s_list == s_result:\n",
    "                return False\n",
    "            else:\n",
    "                s_list = s_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = Solution()\n",
    "x.isValid('[]{[()]{([])}}{}}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Solution:\n",
    "    def isValid(self, s):\n",
    "        \"\"\"\n",
    "        :type s: str\n",
    "        :rtype: bool\n",
    "        \"\"\"\n",
    "        pairs = {']':'[', ')':'(', '}':'{'}\n",
    "        stack = [s[0]]\n",
    "        for i in range(1,len(s)):\n",
    "            stack.append(s[i])\n",
    "            if stack[-1] in pairs and stack[-2] == pairs[stack[-1]]:\n",
    "                stack.pop()\n",
    "                stack.pop()\n",
    "        if len(stack)>=1:\n",
    "            return False\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = Solution()\n",
    "x.isValid('[]{[()]{([])}}{')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
