{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dyjng/anaconda3/lib/python3.6/site-packages/urllib3/contrib/pyopenssl.py:46: DeprecationWarning: OpenSSL.rand is deprecated - you should use os.urandom instead\n",
      "  import OpenSSL.SSL\n"
     ]
    }
   ],
   "source": [
    "import mxnet as mx\n",
    "from mxnet import ndarray as nd\n",
    "from mxnet import autograd as ag\n",
    "from mxnet import init\n",
    "from mxnet import gluon\n",
    "from mxnet.gluon.data import vision\n",
    "from mxnet.gluon.data.vision import transforms\n",
    "from mxnet.gluon.data import DataLoader\n",
    "from mxnet.gluon import nn\n",
    "import datetime\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.dpi'] = 120\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_augs = transforms.Compose([\n",
    "    transforms.Resize(224), \n",
    "    transforms.RandomResizedCrop(224), \n",
    "    transforms.RandomFlipLeftRight(), \n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.2010])\n",
    "])\n",
    "\n",
    "valid_augs = transforms.Compose([\n",
    "    transforms.Resize(224), \n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.2010])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = 'data/cifar10/'\n",
    "batch_size = 32\n",
    "\n",
    "train_ds = vision.ImageFolderDataset(root=data_dir+'train', flag=1)\n",
    "valid_ds = vision.ImageFolderDataset(root=data_dir+'valid', flag=1)\n",
    "\n",
    "train_data = DataLoader(train_ds.transform_first(train_augs), \n",
    "                        batch_size=batch_size, shuffle=True, last_batch='keep')\n",
    "valid_data = DataLoader(valid_ds.transform_first(valid_augs), \n",
    "                        batch_size=batch_size, shuffle=False, last_batch='keep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45000\n",
      "1407\n",
      "(32, 3, 224, 224)\n",
      "(32,)\n",
      "\n",
      "[ 5.  6.  2.  1.  1.  0.  9.  6.  5.  1.  9.  3.  1.  5.  3.  4.  2.  6.\n",
      "  3.  4.  3.  8.  2.  6.  5.  0.  4.  7.  9.  8.  8.  3.]\n",
      "<NDArray 32 @gpu(0)>\n"
     ]
    }
   ],
   "source": [
    "print(len(train_ds))\n",
    "print(len(train_data))\n",
    "for data, label in train_data:\n",
    "    print(data.shape)\n",
    "    print(label.shape)\n",
    "    print(label.astype('float32').as_in_context(mx.gpu(0)))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 设计模型 --Vgg-16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Vgg16(nn.HybridBlock):\n",
    "    def __init__(self, num_classes, verbose=False, **kwargs):\n",
    "        super(Vgg16, self).__init__(**kwargs)\n",
    "        self.verbose = verbose\n",
    "        with self.name_scope():\n",
    "            net = nn.HybridSequential()\n",
    "            for _ in range(2):\n",
    "                net.add(nn.Conv2D(channels=64, kernel_size=3, \n",
    "                                  strides=1, padding=1))\n",
    "                net.add(nn.BatchNorm())\n",
    "                net.add(nn.Activation(activation='relu'))\n",
    "            net.add(nn.MaxPool2D(pool_size=2, strides=2, padding=0))\n",
    "            for _ in range(2):\n",
    "                net.add(nn.Conv2D(channels=128, kernel_size=3, \n",
    "                                  strides=1, padding=1))\n",
    "                net.add(nn.BatchNorm())\n",
    "                net.add(nn.Activation(activation='relu'))\n",
    "            net.add(nn.MaxPool2D(pool_size=2, strides=2, padding=0))\n",
    "            for _ in range(3):\n",
    "                net.add(nn.Conv2D(channels=256, kernel_size=3, \n",
    "                                  strides=1, padding=1))\n",
    "                net.add(nn.BatchNorm())\n",
    "                net.add(nn.Activation(activation='relu'))\n",
    "            net.add(nn.MaxPool2D(pool_size=2, strides=2, padding=0))\n",
    "            for _ in range(3):\n",
    "                net.add(nn.Conv2D(channels=512, kernel_size=3, \n",
    "                                  strides=1, padding=1))\n",
    "                net.add(nn.BatchNorm())\n",
    "                net.add(nn.Activation(activation='relu'))\n",
    "            net.add(nn.MaxPool2D(pool_size=2, strides=2, padding=0))\n",
    "            for _ in range(3):\n",
    "                net.add(nn.Conv2D(channels=512, kernel_size=3, \n",
    "                                  strides=1, padding=1))\n",
    "                net.add(nn.BatchNorm())\n",
    "                net.add(nn.Activation(activation='relu'))\n",
    "            net.add(nn.MaxPool2D(pool_size=2, strides=2, padding=0))\n",
    "            net.add(nn.Flatten())\n",
    "            net.add(nn.Dense(4096))\n",
    "            net.add(nn.BatchNorm())\n",
    "            net.add(nn.Activation(activation='relu'))\n",
    "            net.add(nn.Dropout(0.5))\n",
    "            net.add(nn.Dense(4096))\n",
    "            net.add(nn.BatchNorm())\n",
    "            net.add(nn.Activation(activation='relu'))\n",
    "            net.add(nn.Dropout(0.5))\n",
    "            net.add(nn.Dense(num_classes))\n",
    "        self.net = net\n",
    "        \n",
    "    def hybrid_forward(self, F, x):\n",
    "        for i, layer in enumerate(self.net):\n",
    "            out = layer(x)\n",
    "            x = out\n",
    "            if self.verbose:\n",
    "                print('Block %d, Output: %s' % (i+1, out.shape))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_net(ctx, num_classes):\n",
    "    net = Vgg16(num_classes=num_classes)\n",
    "    net.initialize(ctx=ctx, init=init.Xavier())\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net = Vgg16(100, verbose=True)\n",
    "# net.initialize()\n",
    "# net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for data, label in train_data:\n",
    "#     output = net(data)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train_loss: 4.53740164174, Train_acc: 0.154761904762, Valid_acc: 0.189888535032, Time 00:12:29, lr: 0.010000\n",
      "Epoch 2, Train_loss: 2.56480705933, Train_acc: 0.205246090974, Valid_acc: 0.323248407643, Time 00:07:24, lr: 0.010000\n",
      "Epoch 3, Train_loss: 2.09467909542, Train_acc: 0.286225124378, Valid_acc: 0.383359872611, Time 00:07:24, lr: 0.010000\n",
      "Epoch 4, Train_loss: 1.85151287626, Train_acc: 0.322272565743, Valid_acc: 0.43053343949, Time 00:07:25, lr: 0.010000\n",
      "Epoch 5, Train_loss: 1.89671210647, Train_acc: 0.35743159204, Valid_acc: 0.479299363057, Time 00:07:24, lr: 0.010000\n",
      "Epoch 6, Train_loss: 1.67809216748, Train_acc: 0.395700071073, Valid_acc: 0.504777070064, Time 00:07:25, lr: 0.010000\n",
      "Epoch 7, Train_loss: 1.65086909653, Train_acc: 0.439543354655, Valid_acc: 0.551154458599, Time 00:07:25, lr: 0.010000\n",
      "Epoch 8, Train_loss: 1.53989702041, Train_acc: 0.473214285714, Valid_acc: 0.610071656051, Time 00:07:25, lr: 0.010000\n",
      "Epoch 9, Train_loss: 1.23853374236, Train_acc: 0.50717395167, Valid_acc: 0.649482484076, Time 00:07:25, lr: 0.010000\n",
      "Epoch 10, Train_loss: 1.23469067825, Train_acc: 0.5378242715, Valid_acc: 0.659434713376, Time 00:07:24, lr: 0.010000\n",
      "Epoch 11, Train_loss: 1.39280159634, Train_acc: 0.55223880597, Valid_acc: 0.683718152866, Time 00:07:25, lr: 0.010000\n",
      "Epoch 12, Train_loss: 1.22063766149, Train_acc: 0.571406361052, Valid_acc: 0.731886942675, Time 00:07:25, lr: 0.010000\n",
      "Epoch 13, Train_loss: 1.18229979846, Train_acc: 0.592861584932, Valid_acc: 0.727109872611, Time 00:07:24, lr: 0.010000\n",
      "Epoch 14, Train_loss: 1.20977345922, Train_acc: 0.613450604122, Valid_acc: 0.735668789809, Time 00:07:25, lr: 0.010000\n",
      "Epoch 15, Train_loss: 1.01694750421, Train_acc: 0.629708599858, Valid_acc: 0.752189490446, Time 00:07:24, lr: 0.010000\n",
      "Epoch 16, Train_loss: 1.09434364866, Train_acc: 0.644811656006, Valid_acc: 0.784633757962, Time 00:07:25, lr: 0.010000\n",
      "Epoch 17, Train_loss: 0.921503413292, Train_acc: 0.654939587775, Valid_acc: 0.763335987261, Time 00:07:25, lr: 0.010000\n",
      "Epoch 18, Train_loss: 0.995662471638, Train_acc: 0.667999289268, Valid_acc: 0.802746815287, Time 00:07:25, lr: 0.010000\n",
      "Epoch 19, Train_loss: 0.894748904409, Train_acc: 0.676239339019, Valid_acc: 0.816082802548, Time 00:07:25, lr: 0.010000\n",
      "Epoch 20, Train_loss: 0.841833101848, Train_acc: 0.686656005686, Valid_acc: 0.756170382166, Time 00:07:24, lr: 0.010000\n",
      "Epoch 21, Train_loss: 0.770454924561, Train_acc: 0.696495202559, Valid_acc: 0.823447452229, Time 00:07:25, lr: 0.010000\n",
      "Epoch 22, Train_loss: 0.984045594011, Train_acc: 0.702958422175, Valid_acc: 0.827627388535, Time 00:07:24, lr: 0.010000\n",
      "Epoch 23, Train_loss: 0.814829707196, Train_acc: 0.705246090974, Valid_acc: 0.80851910828, Time 00:07:24, lr: 0.010000\n",
      "Epoch 24, Train_loss: 0.980464193872, Train_acc: 0.713352878465, Valid_acc: 0.800358280255, Time 00:07:25, lr: 0.010000\n",
      "Epoch 25, Train_loss: 0.767070199198, Train_acc: 0.723525230988, Valid_acc: 0.847929936306, Time 00:07:25, lr: 0.010000\n",
      "Epoch 26, Train_loss: 0.807346966211, Train_acc: 0.727567519545, Valid_acc: 0.815684713376, Time 00:07:25, lr: 0.010000\n",
      "Epoch 27, Train_loss: 0.827414783171, Train_acc: 0.731409914712, Valid_acc: 0.849522292994, Time 00:07:24, lr: 0.010000\n",
      "Epoch 28, Train_loss: 0.800185478843, Train_acc: 0.733564321251, Valid_acc: 0.839968152866, Time 00:07:24, lr: 0.010000\n",
      "Epoch 29, Train_loss: 0.7776973822, Train_acc: 0.735074626866, Valid_acc: 0.848128980892, Time 00:07:24, lr: 0.010000\n",
      "Epoch 30, Train_loss: 0.946349788977, Train_acc: 0.7398054371, Valid_acc: 0.858877388535, Time 00:07:24, lr: 0.010000\n",
      "Epoch 31, Train_loss: 0.769211102313, Train_acc: 0.740760483298, Valid_acc: 0.866042993631, Time 00:07:24, lr: 0.010000\n",
      "Epoch 32, Train_loss: 0.739312876205, Train_acc: 0.745580135039, Valid_acc: 0.858081210191, Time 00:07:24, lr: 0.010000\n",
      "Epoch 33, Train_loss: 0.791261943642, Train_acc: 0.745469083156, Valid_acc: 0.847929936306, Time 00:07:24, lr: 0.010000\n",
      "Epoch 34, Train_loss: 0.634899842525, Train_acc: 0.749244847193, Valid_acc: 0.864848726115, Time 00:07:25, lr: 0.010000\n",
      "Epoch 35, Train_loss: 0.719261025928, Train_acc: 0.752576403696, Valid_acc: 0.861464968153, Time 00:07:24, lr: 0.010000\n",
      "Epoch 36, Train_loss: 0.678931439108, Train_acc: 0.75308724236, Valid_acc: 0.855891719745, Time 00:07:24, lr: 0.010000\n",
      "Epoch 37, Train_loss: 0.749963274937, Train_acc: 0.757085110163, Valid_acc: 0.831210191083, Time 00:07:24, lr: 0.010000\n",
      "Epoch 38, Train_loss: 0.690723575731, Train_acc: 0.758284470505, Valid_acc: 0.856687898089, Time 00:07:25, lr: 0.010000\n",
      "Epoch 39, Train_loss: 0.777151515342, Train_acc: 0.760238983653, Valid_acc: 0.86803343949, Time 00:07:26, lr: 0.010000\n",
      "Epoch 40, Train_loss: 0.685439405909, Train_acc: 0.765302949538, Valid_acc: 0.84375, Time 00:07:25, lr: 0.010000\n",
      "Epoch 41, Train_loss: 0.76344976468, Train_acc: 0.76348169865, Valid_acc: 0.866042993631, Time 00:07:27, lr: 0.010000\n",
      "Epoch 42, Train_loss: 0.655062915199, Train_acc: 0.764259061834, Valid_acc: 0.870621019108, Time 00:07:24, lr: 0.010000\n",
      "Epoch 43, Train_loss: 0.642081383764, Train_acc: 0.76368159204, Valid_acc: 0.856289808917, Time 00:07:24, lr: 0.010000\n",
      "Epoch 44, Train_loss: 0.678694049797, Train_acc: 0.768301350391, Valid_acc: 0.870621019108, Time 00:07:23, lr: 0.010000\n",
      "Epoch 45, Train_loss: 0.621650300652, Train_acc: 0.768923240938, Valid_acc: 0.84574044586, Time 00:07:25, lr: 0.010000\n",
      "Epoch 46, Train_loss: 0.591602307745, Train_acc: 0.769189765458, Valid_acc: 0.861664012739, Time 00:07:24, lr: 0.010000\n",
      "Epoch 47, Train_loss: 0.77180011976, Train_acc: 0.77132196162, Valid_acc: 0.841560509554, Time 00:07:23, lr: 0.010000\n",
      "Epoch 48, Train_loss: 0.78673474837, Train_acc: 0.771277540867, Valid_acc: 0.844148089172, Time 00:07:24, lr: 0.010000\n",
      "Epoch 49, Train_loss: 0.620622132149, Train_acc: 0.775564143568, Valid_acc: 0.857085987261, Time 00:07:24, lr: 0.010000\n",
      "Epoch 50, Train_loss: 0.461995610425, Train_acc: 0.817186389481, Valid_acc: 0.916401273885, Time 00:07:24, lr: 0.001000\n",
      "Epoch 51, Train_loss: 0.492743940657, Train_acc: 0.834732587065, Valid_acc: 0.925159235669, Time 00:07:24, lr: 0.001000\n",
      "Epoch 52, Train_loss: 0.511737021553, Train_acc: 0.838708244492, Valid_acc: 0.928343949045, Time 00:07:24, lr: 0.001000\n",
      "Epoch 53, Train_loss: 0.54324960151, Train_acc: 0.844727256574, Valid_acc: 0.927746815287, Time 00:07:25, lr: 0.001000\n",
      "Epoch 54, Train_loss: 0.423745728673, Train_acc: 0.848836176262, Valid_acc: 0.928343949045, Time 00:07:25, lr: 0.001000\n",
      "Epoch 55, Train_loss: 0.571148915, Train_acc: 0.854788557214, Valid_acc: 0.926950636943, Time 00:07:24, lr: 0.001000\n",
      "Epoch 56, Train_loss: 0.422952142724, Train_acc: 0.856520966596, Valid_acc: 0.929737261146, Time 00:07:24, lr: 0.001000\n",
      "Epoch 57, Train_loss: 0.454897509756, Train_acc: 0.856187810945, Valid_acc: 0.927945859873, Time 00:07:24, lr: 0.001000\n",
      "Epoch 58, Train_loss: 0.450607331182, Train_acc: 0.858564321251, Valid_acc: 0.927746815287, Time 00:07:24, lr: 0.001000\n",
      "Epoch 59, Train_loss: 0.432554181023, Train_acc: 0.861962508884, Valid_acc: 0.926552547771, Time 00:07:24, lr: 0.001000\n",
      "Epoch 60, Train_loss: 0.535728514225, Train_acc: 0.867292999289, Valid_acc: 0.927945859873, Time 00:07:24, lr: 0.001000\n",
      "Epoch 61, Train_loss: 0.492911084285, Train_acc: 0.862317874911, Valid_acc: 0.930334394904, Time 00:07:24, lr: 0.001000\n",
      "Epoch 62, Train_loss: 0.544897363428, Train_acc: 0.86151830135, Valid_acc: 0.928343949045, Time 00:07:23, lr: 0.001000\n",
      "Epoch 63, Train_loss: 0.392278952019, Train_acc: 0.868181414357, Valid_acc: 0.929140127389, Time 00:07:23, lr: 0.001000\n",
      "Epoch 64, Train_loss: 0.39243322091, Train_acc: 0.871357498223, Valid_acc: 0.926552547771, Time 00:07:24, lr: 0.001000\n",
      "Epoch 65, Train_loss: 0.364227703353, Train_acc: 0.869869402985, Valid_acc: 0.930334394904, Time 00:07:24, lr: 0.001000\n",
      "Epoch 66, Train_loss: 0.385026398002, Train_acc: 0.87144633973, Valid_acc: 0.928742038217, Time 00:07:25, lr: 0.001000\n",
      "Epoch 67, Train_loss: 0.378421456339, Train_acc: 0.873023276475, Valid_acc: 0.929737261146, Time 00:07:26, lr: 0.001000\n",
      "Epoch 68, Train_loss: 0.418216050974, Train_acc: 0.873089907605, Valid_acc: 0.929737261146, Time 00:07:25, lr: 0.001000\n",
      "Epoch 69, Train_loss: 0.329783446783, Train_acc: 0.875444207534, Valid_acc: 0.928542993631, Time 00:07:25, lr: 0.001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70, Train_loss: 0.340032949322, Train_acc: 0.875799573561, Valid_acc: 0.931727707006, Time 00:07:24, lr: 0.001000\n",
      "Epoch 71, Train_loss: 0.359574322811, Train_acc: 0.877887348969, Valid_acc: 0.928542993631, Time 00:07:24, lr: 0.001000\n",
      "Epoch 72, Train_loss: 0.328870334511, Train_acc: 0.876465884861, Valid_acc: 0.930334394904, Time 00:07:24, lr: 0.001000\n",
      "Epoch 73, Train_loss: 0.379516922244, Train_acc: 0.8786202914, Valid_acc: 0.931329617834, Time 00:07:24, lr: 0.001000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-180ed45c7b85>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m utils.train(net, train_data, valid_data, ctx=ctx, num_epoches=100, softmax_cross_entropy=softmax_cross_entropy,\n\u001b[1;32m      7\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'momentum'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_period\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5e-4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             cost_peroid=10, print_cost=True)\n\u001b[0m",
      "\u001b[0;32m/media/dyjng/数据A1/DL_DYJ/DYJ_Code/CNN_Classification/utils.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(net, train_data, valid_data, ctx, num_epoches, softmax_cross_entropy, optimizer, lr, lr_decay, lr_period, momentum, weight_decay, cost_peroid, print_cost)\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0;31m#trainer.step(batch_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m             \u001b[0mtrain_acc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masscalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;31m#             train_loss += nd.mean(loss).asscalar()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0mcur_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masscalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/mxnet/ndarray/ndarray.py\u001b[0m in \u001b[0;36masscalar\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1809\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1810\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The current array is not a scalar\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1811\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/mxnet/ndarray/ndarray.py\u001b[0m in \u001b[0;36masnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1791\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1792\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_void_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1793\u001b[0;31m             ctypes.c_size_t(data.size)))\n\u001b[0m\u001b[1;32m   1794\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1795\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "softmax_cross_entropy = gluon.loss.SoftmaxCrossEntropyLoss()\n",
    "ctx = mx.gpu(0)\n",
    "net = get_net(ctx, num_classes=10)\n",
    "net.hybridize()\n",
    "\n",
    "utils.train(net, train_data, valid_data, ctx=ctx, num_epoches=100, softmax_cross_entropy=softmax_cross_entropy,\n",
    "            optimizer='momentum', lr=0.01, lr_decay=0.1, lr_period=50, momentum=0.9, weight_decay=5e-4, \n",
    "            cost_peroid=10, print_cost=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "utils.train(net, train_data, valid_data, ctx=ctx, num_epoches=20, softmax_cross_entropy=softmax_cross_entropy,\n",
    "            optimizer='momentum', lr=0.0001, lr_decay=0.01, lr_period=50, momentum=0.9, weight_decay=5e-4, \n",
    "            cost_peroid=10, print_cost=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
